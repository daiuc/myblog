---
title: "My HPC workflow setup"
author: "Chao"
date: "2022-09-25"
categories: ["tips", "data science", "python", "jupyter", "rstudio"]
image: "ZmZEkO-pb7M.jpg"
---

This workflow aims to achieve remote data analysis on high performance computing clusters. Main tools involved are:

-   `code-server`
-   `singularity` and `docker` image
-   `snakemake`
-   `conda`

### Set up code-server

The purpose of code-server is to enable remote development. Once set up, you can run `vscode` from browser.

#### 1. Download code-server binary

Download the latest binary from [code-server github page](https://github.com/coder/code-server) and install to your preferred local path, e.g. `$HOME/bin`.

#### 2. Install extensions

Install desired extensions with `code-server --install-extension`. Search extensions on [Open VSX Registry](https://open-vsx.org). For example, here are my installed extensions:

::: {.panel-tabset}

## 
```
    akamud.vscode-theme-onelight
    Ikuyadeu.r
    ms-python.python
    ms-toolsai.jupyter
    ms-toolsai.jupyter-keymap
    ms-toolsai.jupyter-renderers
    PKief.material-icon-theme
    quarto.quarto
    RDebugger.r-debugger
    snakemake.snakemake-lang
    streetsidesoftware.code-spell-checker
    vscodevim.vim
    zhuangtongfa.material-theme
```
:::

#### 3. Configurations

Configure `code-server` with a config yaml file at `$HOME/.config/code-server/config.yaml`.

::: {.panel-tabset}

##
```
bind-addr: {IP}:{PORT}
#auth: none
auth: password
rashed-password: YOUR-HASHED-PASSWORD
cert: true
cert-key: /path/to/your/cert/if/cert/is/set/to/true
```
:::

#### 4. start code-server

Simply start code-server with `code-server PATH/TO/YOUR/WORKSPACE`

---

### `conda` and `snakemake`

Install `conda` to create appropriate environment. For instance, I created a `smk` environment and installed `python 3.9`, `jupyterlab`, `r-base 4.1.0` and `snakemake 6.12.3`


---

### `singularity` and `docker` image

I built a docker image on my mac based on the [`rocker/rstudio`](https://hub.docker.com/r/rocker/rstudio) docker image. Because `docker` requires `root`, it is not available on HPCs. Thus I built a `sif` image using `singularity` (now re-branded as `apptainer`). The purpose of this container is to run my own `rstudio server` on HPC.

I used `singularity` to bind `$HOME` and `scratch` directory. When running the container, instead of using the r binary in the container, I used the r binary in `smk` environment. This ensures that rstudio run in the container leverages the same R and R library.

#### 1. Build a sif from docker image

```
singularity pull bajiame/rstudio:R4.1.0-Rstudio554
```

#### 2. Create rstudio server temp directory

Rstudio server cache some temp data thus we need to create some directories before running the container. Make sure the following binding paths exist on the host OS.

::: {.panel-tabset}
## 
```
    --bind $TMPDIR/var/lib:/var/lib/rstudio-server \
    --bind $TMPDIR/var/run:/var/run/rstudio-server \
    --bind $TMPDIR/tmp:/tmp \
    --bind $TMPDIR/database.conf:/etc/rstudio/database.conf \
```
:::

#### 3. Configure sbatch scricpt

Configure an sbatch script similar to below.

::: {.panel-tabset}
## 
```
## set SIF
SIF="PATH/TO/rstudio_R4.1.0-Rstudio554.sif"
TMPDIR={YOUR_TEMP_DIR_FOR_RSTUDIO}

# set conda, R, python binary
CONDA_PREFIX={YOUR_CONDA_ENV_PATH}
R_BIN=$CONDA_PREFIX/bin/R
PY_BIN=$CONDA_PREFIX/bin/python

## export conda environment to container
export SINGULARITYENV_USER={YOUR_USER_NAME}
export SINGULARITYENV_RSTUDIO_WHICH_R=${R_BIN}
export SINGULARITYENV_CONDA_PREFIX=${CONDA_PREFIX}
export SINGULARITYENV_PATH={YOUR_PATHS_TO_APPEND}
export SINGULARITYENV_CACHEDIR="{YOUR/singularity_cache}"

RSTUDIO_SERVER_USER=chaodai # change to your own

## run container app
PASSWORD='{CHOSE_YOUR_PASSWORD}' singularity exec \
    --bind $TMPDIR/var/lib:/var/lib/rstudio-server \
    --bind $TMPDIR/var/run:/var/run/rstudio-server \
    --bind $TMPDIR/tmp:/tmp \
    --bind $TMPDIR/database.conf:/etc/rstudio/database.conf \
    --bind /sys/fs/cgroup/:/sys/fs/cgroup/:ro \
    --bind {YOUR_HOME_DIR}:/home/rstudio \
    --bind /project2/{LAB}:/project2/{LAB} \
    $SIF \
    rserver --server-user $RSTUDIO_SERVER_USER \
        --rsession-which-r=${R_BIN} \
        --www-port=${RPORT} \
        --auth-none=0 \
        --auth-pam-helper-path=pam-helper \
        --auth-timeout-minutes=0 \
        --auth-stay-signed-in-days=30 \
        --secure-cookie-key-file={/CREATE_YOUR/secure-cookie-key}
```
:::

#### Create compute node and start container

Use your sbatch script to request a compute node and start your rstudio server.


In my `sbatch` script, I essentially run these commands:

-   first, activate `smk` environment
-   second, start `jupyter lab`, note this is run directly on compute node
-   finally, start `singularity` container and run `rstudio`. Note `rstudio` is run inside a container on the compute node

Note, since compute node is behind firewall, I need to access jupyter and rstudio servers via VPN or port forwarding.

---

### Typical workflow

After the set up, the typical workflow works like this:

1.  SSH into login node, and spin up `code-server`. Note this step is no longer required once the server is up and running.

2.  Access `vscode` via the `code-server` URL on the login node.

3.  Submit the `sbatch` script to spin up both `jupyter lab` and `rstudio` servers on the same compute node

4.  To access `jupyter` and `rstudio` there are two options:

    1.  VPN
    2.  port-forward using SSH or vscode desktop app.
